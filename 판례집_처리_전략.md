# 1000페이지 판례집 처리 전략

## 📊 문제 분석

### 현황
- **파일 크기**: 1000페이지 PDF
- **예상 텍스트량**: 약 500,000-1,000,000 자 (50만-100만 자)
- **토큰 변환**: 약 125,000-250,000 tokens

### 문제점
1. **프롬프트 토큰 제한**: Gemini 2.5 Pro는 입력 토큰 제한이 있음 (약 128K-1M)
2. **비용**: 전체를 매번 처리하면 비용 폭증
3. **관련성**: 주제와 무관한 판례까지 포함

---

## 🎯 추천 전략: 3단계 접근

### **Phase 1: 간단한 키워드 필터링 (즉시 구현 가능)** ⭐ 우선

**목표**: 빠르게 구현, 비용 최소화

**방법**:
1. PDF 텍스트 추출 (`pdf-parse`)
2. 사건번호 기준으로 판례 분할
3. 각 판례의 제목/요지 추출
4. 주제/키워드와 매칭되는 판례만 선별 (최대 3-5개)
5. 선별된 판례만 프롬프트에 포함

**장점**:
- 구현 간단 (1-2일)
- 추가 인프라 불필요
- 비용 거의 없음

**단점**:
- 키워드 매칭 정확도 제한적
- 관련 판례를 놓칠 수 있음

**예상 토큰**: 주제별 3-5개 판례 = 약 5,000-10,000 tokens

---

### **Phase 2: 벡터 검색 (추천, 중기)** ⭐⭐⭐ 최적

**목표**: 정확도 최대화, 확장성 확보

**방법**:
1. PDF 텍스트 추출
2. 판례별로 분할
3. 각 판례를 임베딩 벡터로 변환 (Gemini Embedding API)
4. Supabase pgvector에 저장
5. 주제/키워드를 벡터로 변환
6. 유사도 검색으로 관련 판례 3-5개만 가져오기

**장점**:
- 의미 기반 검색 (키워드 매칭보다 정확)
- 한 번만 임베딩 생성 (비용 1회성)
- 이후 검색은 매우 저렴
- 1000페이지 확장 가능

**단점**:
- 초기 구현 복잡도 높음 (3-5일)
- Supabase pgvector 설정 필요

**예상 비용**:
- 초기 임베딩: 1000개 판례 × 1000 tokens = 1M tokens (1회성)
- 검색당: 주제 벡터화 + 검색 = 약 1,000 tokens
- **매 블로그 생성당 약 $0.001 미만** ✅

---

### **Phase 3: 하이브리드 (장기)** 

**목표**: 정확도 + 속도 최적화

**방법**:
1. 벡터 검색으로 후보 판례 10개 선별
2. LLM으로 최종 3-5개 선별 (관련도 평가)
3. 선별된 판례만 프롬프트에 포함

---

## 💡 즉시 구현 가능한 Phase 1 방법

### 1단계: PDF 파싱 스크립트

```typescript
// scripts/parse-precedents.ts
import pdf from 'pdf-parse'
import fs from 'fs'
import path from 'path'

interface Precedent {
  caseNumber: string  // "제2023-1234호"
  title: string
  content: string
  keywords: string[]  // 자동 추출
}

async function parsePrecedentsPDF(filePath: string): Promise<Precedent[]> {
  const dataBuffer = fs.readFileSync(filePath)
  const data = await pdf(dataBuffer)
  
  // 사건번호 패턴으로 판례 분할
  // 예: "금융분쟁조정위원회 제2023-1234호"
  const casePattern = /(제\d{4}-\d+호)/g
  const sections = data.text.split(/(제\d{4}-\d+호)/g)
  
  const precedents: Precedent[] = []
  
  for (let i = 0; i < sections.length; i += 2) {
    if (sections[i + 1]) { // 사건번호가 있는 경우
      const caseNumber = sections[i + 1]
      const content = sections[i + 2] || ''
      
      // 제목 추출 (첫 2-3줄)
      const lines = content.split('\n').filter(l => l.trim())
      const title = lines.slice(0, 3).join(' ').substring(0, 200)
      
      // 키워드 추출 (보험 용어 자동 감지)
      const keywords = extractKeywords(content)
      
      precedents.push({
        caseNumber,
        title,
        content: content.substring(0, 5000), // 최대 5000자
        keywords
      })
    }
  }
  
  return precedents
}

function extractKeywords(text: string): string[] {
  // 보험 관련 키워드 추출
  const insuranceTerms = [
    '암보험', '실손보험', '운전자보험', '종신보험',
    '보험금', '보험약관', '면책', '분쟁조정',
    '진단비', '수술비', '입원비'
  ]
  
  return insuranceTerms.filter(term => text.includes(term))
}

// JSON으로 저장
async function main() {
  const precedents = await parsePrecedentsPDF('./data/보험분쟁조정사례집.pdf')
  fs.writeFileSync(
    './data/precedents.json',
    JSON.stringify(precedents, null, 2)
  )
  console.log(`✅ ${precedents.length}개 판례 추출 완료`)
}

main()
```

### 2단계: 키워드 매칭 필터링

```typescript
// lib/precedents.ts
import precedentsData from '@/data/precedents.json'

interface Precedent {
  caseNumber: string
  title: string
  content: string
  keywords: string[]
}

export function findRelevantPrecedents(
  topic: string,
  keywords: string,
  maxResults: number = 3
): Precedent[] {
  const searchText = `${topic} ${keywords}`.toLowerCase()
  const searchTerms = searchText.split(/[\s,]+/).filter(t => t.length > 1)
  
  // 점수 계산
  const scored = precedentsData.map((precedent: Precedent) => {
    let score = 0
    
    // 키워드 매칭 점수
    searchTerms.forEach(term => {
      if (precedent.title.toLowerCase().includes(term)) score += 3
      if (precedent.content.toLowerCase().includes(term)) score += 1
      if (precedent.keywords.some(k => k.includes(term))) score += 2
    })
    
    return { precedent, score }
  })
  
  // 점수 순 정렬, 상위 N개만
  return scored
    .sort((a, b) => b.score - a.score)
    .filter(item => item.score > 0)
    .slice(0, maxResults)
    .map(item => item.precedent)
}
```

### 3단계: 블로그 생성에 통합

```typescript
// app/api/generate/route.ts
import { findRelevantPrecedents } from '@/lib/precedents'

// ... 기존 코드 ...

// 주제 관련 판례 찾기
const relevantPrecedents = findRelevantPrecedents(topic, keywords, 3)

// 프롬프트에 포함
const promptData = {
  // ... 기존 데이터 ...
  precedents: relevantPrecedents.map(p => ({
    caseNumber: p.caseNumber,
    title: p.title,
    summary: p.content.substring(0, 1000) // 요약
  }))
}
```

---

## 📋 구현 순서

### Step 1: PDF 파싱 (1회 실행)
```bash
npm install pdf-parse
npm install --save-dev @types/pdf-parse
tsx scripts/parse-precedents.ts
```

### Step 2: JSON 데이터 생성
- `data/precedents.json` 생성 (1000개 판례)

### Step 3: 필터링 로직 구현
- `lib/precedents.ts` 생성

### Step 4: 블로그 생성 통합
- `app/api/generate/route.ts` 수정
- 프롬프트에 판례 포함

---

## 💰 비용 비교

| 방법 | 초기 비용 | 블로그당 비용 | 정확도 |
|------|----------|--------------|--------|
| Vision API | - | $5-10 | 높음 |
| Phase 1 (키워드) | 무료 | 무료 | 중간 |
| Phase 2 (벡터) | $1-2 (1회) | $0.001 | 매우 높음 |

---

## 🎯 추천: Phase 1부터 시작

**이유**:
1. 즉시 구현 가능 (오늘 시작 가능)
2. 비용 거의 없음
3. 효과 검증 가능
4. 나중에 Phase 2로 업그레이드 용이

**다음 단계**:
1. PDF 파일 위치 확인
2. `pdf-parse` 설치 및 파싱 스크립트 작성
3. 판례 데이터 JSON 생성
4. 필터링 로직 구현
5. 블로그 생성 통합

PDF 파일 경로를 알려주시면 즉시 구현 시작하겠습니다!

